name: Scrape DziaÅ‚ki

on:
  schedule:
    # Co 12 godzin: o 6:00 i 18:00 UTC (8:00 i 20:00 czasu polskiego)
    - cron: '0 6,18 * * *'
  workflow_dispatch:  # MoÅ¼liwoÅ›Ä‡ rÄ™cznego uruchomienia

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: ğŸ“¥ Checkout repo
        uses: actions/checkout@v4

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: scraper/requirements.txt

      - name: ğŸ“¦ Install dependencies
        run: pip install -r scraper/requirements.txt

      - name: ğŸŒ Install Playwright browsers
        run: playwright install chromium --with-deps

      - name: ğŸ” Run scraper
        run: python scraper/scraper.py

      - name: ğŸ“Š Show results
        run: |
          echo "=== Wyniki scrapowania ==="
          python -c "
          import json
          with open('docs/data.json') as f:
              d = json.load(f)
          print(f'ÅÄ…cznie ofert: {d[\"total\"]}')
          sources = {}
          areas = {}
          for item in d['listings']:
              sources[item['source']] = sources.get(item['source'], 0) + 1
              areas[item['location_area']] = areas.get(item['location_area'], 0) + 1
          for k,v in sources.items():
              print(f'  {k}: {v}')
          print()
          for k,v in areas.items():
              print(f'  {k}: {v}')
          "

      - name: ğŸ’¾ Commit & push data
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add docs/data.json
          git diff --staged --quiet || git commit -m "ğŸ¡ Update listings $(date -u '+%Y-%m-%d %H:%M UTC')"
          git push
