# ğŸ¡ DziaÅ‚ki PL â€” Scraper + Aplikacja webowa

Automatyczny scraper ogÅ‚oszeÅ„ dziaÅ‚ek z portali Otodom, OLX, Gratka i Nieruchomosci-online dla okolic **Rzeszowa (30 km)** i **Zakopanego (20 km)**.  
Dane aktualizowane co 12 godzin przez **GitHub Actions**, wyÅ›wietlane przez **GitHub Pages**.

---

## ğŸš€ Instalacja krok po kroku

### 1. UtwÃ³rz repozytorium na GitHub

1. Zaloguj siÄ™ na [github.com](https://github.com)
2. Kliknij **"New repository"**
3. Nazwa: `dzialki-scraper` (lub dowolna)
4. Ustaw jako **Public** (wymagane dla darmowego GitHub Pages)
5. Kliknij **"Create repository"**

### 2. Wgraj pliki

MoÅ¼esz to zrobiÄ‡ przez interfejs GitHub (przeciÄ…gnij i upuÅ›Ä‡ pliki) lub przez terminal:

```bash
git clone https://github.com/TWÃ“J_LOGIN/dzialki-scraper.git
cd dzialki-scraper

# Skopiuj wszystkie pliki z tego archiwum do katalogu
# NastÄ™pnie:
git add .
git commit -m "Pierwszy commit"
git push
```

### 3. WÅ‚Ä…cz GitHub Pages

1. W repozytorium przejdÅº do **Settings** â†’ **Pages**
2. W sekcji **"Source"** wybierz **"Deploy from a branch"**
3. Branch: `main`, Folder: `/docs`
4. Kliknij **Save**
5. Po chwili Twoja aplikacja bÄ™dzie dostÄ™pna pod adresem:
   `https://TWÃ“J_LOGIN.github.io/dzialki-scraper/`

### 4. Uruchom pierwsze scrapowanie rÄ™cznie

1. PrzejdÅº do **Actions** w repozytorium
2. Kliknij **"Scrape DziaÅ‚ki"** po lewej
3. Kliknij **"Run workflow"** â†’ **"Run workflow"**
4. Poczekaj ~5 minut
5. OdÅ›wieÅ¼ stronÄ™ aplikacji â€” pojawiÄ… siÄ™ pierwsze oferty! ğŸ‰

---

## â° Harmonogram automatyczny

Scraper uruchamia siÄ™ automatycznie:
- **08:00** czasu polskiego (6:00 UTC)
- **20:00** czasu polskiego (18:00 UTC)

MoÅ¼esz zmieniÄ‡ godziny w pliku `.github/workflows/scrape.yml` (format cron UTC).

---

## ğŸ“ Struktura projektu

```
dzialki-scraper/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ scrape.yml        # Harmonogram GitHub Actions
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ scraper.py            # GÅ‚Ã³wny skrypt scrapujÄ…cy
â”‚   â””â”€â”€ requirements.txt      # ZaleÅ¼noÅ›ci Pythona
â””â”€â”€ docs/                     # GitHub Pages
    â”œâ”€â”€ index.html            # Aplikacja webowa
    â””â”€â”€ data.json             # Dane ofert (generowane automatycznie)
```

---

## ğŸ”§ Dostosowanie lokalizacji

W pliku `scraper/scraper.py` znajdÅº sekcjÄ™ `LOCATIONS` i zmodyfikuj wedÅ‚ug potrzeb.
MoÅ¼esz zmieniÄ‡ promieÅ„ wyszukiwania lub dodaÄ‡ nowe miasta.

---

## âš ï¸ Uwagi

- Portale mogÄ… zmieniaÄ‡ strukturÄ™ HTML â€” scraper moÅ¼e wymagaÄ‡ aktualizacji
- Zbyt czÄ™ste scraping moÅ¼e skutkowaÄ‡ tymczasowym blokowaniem IP
- Upewnij siÄ™, Å¼e scraping jest zgodny z regulaminami portali
